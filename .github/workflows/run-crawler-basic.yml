name: Scheduled Basic Crawler

on:
  schedule:
    - cron: '*/15 * * * *'
  workflow_dispatch:

jobs:
  run-crawler-basic:
    runs-on: ubuntu-latest
    env:
      API_URL: ${{ secrets.API_URL }}
      GIST_TOKEN: ${{ secrets.GIST_TOKEN }}
      DISCORD_WEBHOOK_URL: ${{ secrets.DISCORD_WEBHOOK_URL }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'

      - name: Install dependencies
        run: npm install

      - name: Prepare .env file
        run: |
          cat <<'EOF' > .env
          API_URL=${API_URL}
          GIST_TOKEN=${GIST_TOKEN}
          DISCORD_WEBHOOK_URL=${DISCORD_WEBHOOK_URL}
          EOF

      - name: Run crawler
        env:
          MODE: BASIC
          MAX_POST_AGE_MINUTES: 18
          SILENT_MODE: "true"
        run: node --env-file=.env app.js
